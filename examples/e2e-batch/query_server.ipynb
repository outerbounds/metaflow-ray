{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: METAFLOW_PROFILE=oleg2\n"
     ]
    }
   ],
   "source": [
    "%env METAFLOW_PROFILE=oleg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the server\n",
    "\n",
    "```\n",
    "serve run server:batch_preds\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from base import TabularBatchPrediction as TBP\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello_world_output = requests.post(\"http://localhost:8000\").json()\n",
    "assert hello_world_output['response'] == \"Hello World!\", \"Are you sure you're running the server?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data() -> pd.DataFrame:\n",
    "    tbp = TBP()\n",
    "    _, valid_dataset, test_dataset = tbp.load_dataset()\n",
    "    df = test_dataset.to_pandas()\n",
    "    df[\"id\"] = df.index\n",
    "    return df, valid_dataset.to_pandas()[\"target\"].values\n",
    "\n",
    "\n",
    "def prepare_post_body(batch: pd.DataFrame) -> dict:\n",
    "    id_to_batch = {}\n",
    "    for record in batch:\n",
    "        _id = record.pop(\"id\")\n",
    "        id_to_batch[_id] = record\n",
    "    return id_to_batch\n",
    "\n",
    "\n",
    "def query_predict_endpoint(batch_size=5, df=None):\n",
    "    if df is None:\n",
    "        df = get_data()\n",
    "    batch = df.sample(batch_size).to_dict(\"records\")\n",
    "    id_to_batch_features = prepare_post_body(batch)\n",
    "    output = requests.post(\n",
    "        \"http://localhost:8000/predict/\", data=json.dumps(id_to_batch_features)\n",
    "    ).json()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No dataset name or loader provided. Using default breast_cancer.csv dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 17:46:22,925\tINFO worker.py:1612 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8267 \u001b[39m\u001b[22m\n",
      "2023-09-14 17:46:24,521\tINFO read_api.py:374 -- To satisfy the requested parallelism of 20, each read task output will be split into 20 smaller blocks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dataset]: Run `pip install tqdm` to enable progress reporting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 17:46:25,970\tINFO streaming_executor.py:92 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(<lambda>)]\n",
      "2023-09-14 17:46:25,971\tINFO streaming_executor.py:93 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-09-14 17:46:25,971\tINFO streaming_executor.py:95 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    }
   ],
   "source": [
    "df, true_targets = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \"Prediction proba for sample input {} is {}. True target is {}.\"\n",
    "output = query_predict_endpoint(batch_size=5, df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction proba for sample input 100 is 0.11638931185007095. True target is 0.\n",
      "Prediction proba for sample input 55 is 0.8022734522819519. True target is 1.\n",
      "Prediction proba for sample input 155 is 0.8228343725204468. True target is 1.\n",
      "Prediction proba for sample input 75 is 0.8228343725204468. True target is 1.\n",
      "Prediction proba for sample input 126 is 0.8797837495803833. True target is 1.\n"
     ]
    }
   ],
   "source": [
    "for id, proba in output.items():\n",
    "    print(msg.format(id, proba, true_targets[int(id)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is running on the `/predict` endpoint on the server?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 17:47:14,732\tINFO streaming_executor.py:92 -- Executing DAG InputDataBuffer[Input] -> ActorPoolMapOperator[MapBatches(StandardScaler._transform_pandas)->MapBatches(ScoringWrapper)]\n",
      "2023-09-14 17:47:14,734\tINFO streaming_executor.py:93 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-09-14 17:47:14,735\tINFO streaming_executor.py:95 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2023-09-14 17:47:14,766\tINFO actor_pool_map_operator.py:117 -- MapBatches(StandardScaler._transform_pandas)->MapBatches(ScoringWrapper): Waiting for 1 pool actors to start...\n",
      "2023-09-14 17:47:15,747\tWARNING actor_pool_map_operator.py:267 -- To ensure full parallelization across an actor pool of size 1, the specified batch size should be at most 2. Your configured batch size for this operator was 4096.\n"
     ]
    }
   ],
   "source": [
    "from ray.train.xgboost import XGBoostPredictor\n",
    "import ray\n",
    "from ray.train.batch_predictor import BatchPredictor\n",
    "from metaflow import Run, Flow\n",
    "\n",
    "\n",
    "def select_from_checkpoint_registry(flow_name=\"Train\"):\n",
    "    flow = Flow(flow_name)\n",
    "    run = flow.latest_successful_run\n",
    "    result = run.data.result\n",
    "    return result.checkpoint\n",
    "\n",
    "\n",
    "# duplicated in `query_predict_endpoint` above\n",
    "batch_size = 2\n",
    "if df is None:\n",
    "    df = get_data()\n",
    "batch = df.sample(batch_size).to_dict(\"records\")\n",
    "id_to_batch_features = prepare_post_body(batch)\n",
    "\n",
    "features = ray.data.from_items(list(id_to_batch_features.values()))\n",
    "checkpoint = select_from_checkpoint_registry()\n",
    "predictor = BatchPredictor.from_checkpoint(checkpoint, XGBoostPredictor)\n",
    "preds = predictor.predict(features).to_pandas()[\"predictions\"].values\n",
    "preds_payload = dict(zip(id_to_batch_features.keys(), preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{54: 0.89597195, 155: 0.89597195}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_payload"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
